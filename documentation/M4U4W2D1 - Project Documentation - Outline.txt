# M4U4W2D1 -- Project Documentation - Outline


# Wetlands MVP v2 Solo (VSC Copilot (Claude Sonnet 4))

A minimal viable product for wetland education that uses AI vision to analyze and describe wetland images, helping users learn about water ecosystems and their importance.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Setup Guide](#setup-guide)
- [Dependencies](#dependencies)
- [Usage Instructions](#usage-instructions)
- [API Keys](#api-keys)
- [Deployment Instructions](#deployment-instructions)
- [Developer Notes](#developer-notes)
- [Troubleshooting](#troubleshooting)

## Overview

This project is an educational tool that:
- **Visitors**: Learn about water and wetlands importance through AI-powered image analysis
- **Uploaders**: Gain understanding of water issues and wetlands' role through interactive photo analysis

The current MVP demonstrates AI capability by:
1. Manually placing images in `/backend/images_preUpload/`
2. Hardcoding filenames in FastAPI
3. Sending image paths to Ollama (LLaVA vision model)
4. Receiving AI-generated descriptions focused on wetland education
5. Returning structured JSON responses
6. Displaying results (future React frontend integration)

## ğŸ›  Setup Guide

### Prerequisites
- Python 3.8+
- Ollama installed locally
- LLaMA 3.2 Vision model (`llama3.2-vision`)

### Installation Steps

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd Wetlands-MVP_v2_solo
   ```

2. **Install Python dependencies**
   ```bash
   pip install fastapi uvicorn ollama
   ```

3. **Install and setup Ollama**
   ```bash
   # Install Ollama (visit https://ollama.ai for platform-specific instructions)
   # Pull the required vision model
   ollama pull llama3.2-vision
   ```

4. **Verify Ollama is running**
   ```bash
   ollama serve
   ```

## ğŸ“¦ Dependencies

### Required Python Packages
- `fastapi` - Web framework for building APIs
- `uvicorn` - ASGI server for FastAPI
- `ollama` - Python client for Ollama AI models

### AI Models
- `llama3.2-vision` - Vision-language model for image analysis

### Future Dependencies (Planned)
- PostgreSQL database
- React frontend
- File upload handling
- Authentication system

## ğŸš€ Usage Instructions

### Running the Backend

1. **Start the FastAPI server**
   ```bash
   cd backend
   uvicorn main:app --host 127.0.0.1 --port 8000 --reload
   ```

2. **Test the API**
   - Open browser to `http://127.0.0.1:8000`
   - Should see: `{"message": "Hello, World!"}`

### Image Analysis

1. **Place image files** in [`backend/images_preUpload/`](backend/images_preUpload/)

2. **Update image path** in [`model_RAG_response.py`](backend/model_RAG_response.py):
   ```python
   image_path = 'images_preUpload/your-image-name.png'
   ```

3. **Run image analysis**
   ```bash
   cd backend
   python model_RAG_response.py
   ```

### Expected Output
The AI will provide:
- Image description with common names (not scientific)
- Educational fact suitable for 10-second reading
- Focus on wetland ecosystems and water importance

## ğŸ”‘ API Keys

### Current Setup
- No external API keys required
- Uses local Ollama installation

### Future Requirements
- Database connection credentials (`.env` file)
- Potential cloud AI service keys
- Image storage service credentials

## ğŸš€ Deployment Instructions

### Local Development
```bash
# Terminal 1: Start Ollama
ollama serve

# Terminal 2: Start FastAPI
cd backend
uvicorn main:app --host 127.0.0.1 --port 8000 --reload
```

### Production Deployment (Future)
1. **Environment Setup**
   - Configure production database
   - Set up environment variables
   - Install dependencies on server

2. **Server Configuration**
   ```bash
   uvicorn backend.main:app --host 0.0.0.0 --port 8000
   ```

3. **Database Setup**
   - PostgreSQL configuration
   - Migration scripts
   - Connection pooling

## ğŸ‘¥ Developer Notes

### Project Structure
```
Wetlands-MVP_v2_solo/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application entry point
â”‚   â”œâ”€â”€ model_RAG_response.py # AI image analysis logic
â”‚   â”œâ”€â”€ image_util.py        # Base64 encoding utilities
â”‚   â”œâ”€â”€ images_preUpload/    # Image storage directory
â”‚   â””â”€â”€ documentation/       # Project documentation
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
```

### Key Files
- [`main.py`](backend/main.py) - FastAPI routes and server configuration
- [`model_RAG_response.py`](backend/model_RAG_response.py) - Ollama integration and prompt engineering
- [`image_util.py`](backend/image_util.py) - Image processing utilities

### Development Priorities
1. **Next Phase Options**:
   - File upload functionality
   - Database integration
   - User authentication
   - Frontend development (React)

2. **Code Quality**:
   - Add error handling
   - Implement logging
   - Create unit tests
   - API documentation

### Prompt Engineering
The AI prompt is designed to:
- Act as a nature guide focused on wetlands
- Provide 5th-grade level explanations (10-second read time)
- Emphasize ecological importance of wetlands
- Avoid encouraging risky behavior near water

## ğŸ”§ Troubleshooting

### Common Issues

**1. Ollama Connection Failed**
```bash
# Solution: Ensure Ollama is running
ollama serve
# Check if model is available
ollama list
```

**2. Image File Not Found**
- Verify image path in [`model_RAG_response.py`](backend/model_RAG_response.py)
- Check file exists in `images_preUpload/` directory
- Ensure correct file permissions

**3. FastAPI Import Errors**
```bash
# Solution: Install missing dependencies
pip install fastapi uvicorn
```

**4. Model Not Available**
```bash
# Solution: Pull the required model
ollama pull llama3.2-vision
```

### Debug Steps
1. Check Ollama service status
2. Verify Python environment and packages
3. Confirm image file paths and permissions
4. Review error logs in terminal output

### Getting Help
- Check [`documentation/`](backend/documentation/) folder for detailed guides
- Review code comments for implementation details
- Test with sample images in `images_preUpload/`

## ğŸ“ Recommended Test Locations
As noted in [`Sites_recomm_preGIS.md`](backend/documentation/Sites_recomm_preGIS.md):
- Wolf River Greenway locations
- Bridge and culvert areas with safe access
- Areas suitable for educational photography

---

**Note**: This is an MVP focused on demonstrating AI capabilities. Future versions will include full web application functionality, user uploads, and comprehensive wetland education features.





# ChatGPT
# ğŸŒ¿ Wetlands Monitoring Web Application

*A citizen-science platform for mapping and monitoring small, localized wetlands*

---

## ğŸ“Œ Project Overview

Small, localized wetlands play a critical role in **water filtration** and **flood mitigation**, yet many remain unmapped and under-monitored.

This web application enables **citizen scientists** to submit map-ready environmental observations quickly and reliably, helping build a shared dataset that supports conservation, research, and community awareness.

**Core Goals**

* Increase public awareness of wetlands as water-quality indicators
* Enable structured, standardized environmental data submission
* Produce exportable, GIS-ready datasets
* Support long-term conservation and infrastructure planning

---

# ğŸ›  Setup Guide

## 1ï¸âƒ£ Prerequisites

* Node.js (v18+ recommended)
* npm or yarn
* Git
* PostgreSQL (or chosen database)
* Optional: Docker

---

## 2ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/your-org/wetlands-project.git
cd wetlands-project
```

---

## 3ï¸âƒ£ Install Dependencies

```bash
npm install
```

---

## 4ï¸âƒ£ Environment Variables

Create a `.env` file in the root directory:

```env
DATABASE_URL=your_database_connection_string
MAPS_API_KEY=your_maps_api_key
JWT_SECRET=your_secret_key
PORT=3000
```

See **API Keys section** below for more detail.

---

## 5ï¸âƒ£ Database Setup

Run migrations:

```bash
npm run migrate
```

Seed database (optional):

```bash
npm run seed
```

---

## 6ï¸âƒ£ Start Development Server

```bash
npm run dev
```

Visit:

```
http://localhost:3000
```

---

# ğŸš€ Usage Instructions

## ğŸ‘¤ For Visitors

* View wetland map
* Explore previously submitted observations
* Learn about:

  * Water quality indicators
  * Native plants and animals
  * Flood mitigation benefits

## ğŸ§‘â€ğŸ”¬ For Citizen Scientists (Actors)

1. Click **Submit Observation**
2. Allow location access (or manually enter coordinates)
3. Upload image(s)
4. Complete structured form:

   * Water presence
   * Vegetation type
   * Wildlife indicators
   * Signs of pollution
5. Submit for review

Submissions are:

* Validated
* Stored in database
* Exportable in CSV/GeoJSON format

---

# ğŸ§‘â€ğŸ’» Developer Notes

## ğŸ—‚ Suggested Database Tables

* `users`
* `observations`
* `images`
* `wetland_types`
* `species`
* `admin_reviews`

## ğŸ§  Architecture Overview

Frontend:

* React (or chosen framework)
* Map integration (Leaflet/Google Maps API)
* Image preview + optional Base64 encoding (Phase 1 lightweight implementation)

Backend:

* Node.js + Express
* RESTful API routes (CRUD)
* Authentication middleware
* File handling (local or cloud storage)

Database:

* PostgreSQL (preferred)
* Spatial extension recommended (PostGIS)

---

# ğŸ”‘ API Keys

Store in `.env` file. Do NOT commit to version control.

Common Required Keys:

* Google Maps API Key (for map rendering)
* Mapbox Token (if using Mapbox instead)
* Cloud storage key (e.g., AWS S3)
* JWT Secret (authentication)

### Best Practices

* Use `.env.example`
* Rotate keys periodically
* Restrict domain usage in API dashboards

---

# ğŸŒ Deployment Instructions

## Option A: Vercel (Frontend) + Railway/Render (Backend)

1. Push to GitHub
2. Connect repo to deployment platform
3. Add environment variables in dashboard
4. Configure production database
5. Deploy

---

## Option B: Docker Deployment

Build image:

```bash
docker build -t wetlands-app .
```

Run container:

```bash
docker run -p 3000:3000 wetlands-app
```

---

## Option C: Traditional VPS

* Install Node + PostgreSQL
* Pull repo
* Install dependencies
* Configure `.env`
* Use PM2 to manage process:

```bash
pm2 start server.js
```

---

# ğŸ“¦ Dependencies

## Core

* express
* react
* axios
* dotenv
* jsonwebtoken
* bcrypt
* multer (for image uploads)

## Database

* pg
* sequelize or prisma (optional ORM)

## Mapping

* leaflet or Google Maps SDK
* geospatial utilities (turf.js)

---

# ğŸ§© Troubleshooting Tips

## App wonâ€™t start

* Check `.env` file
* Confirm `PORT` not in use
* Run `npm install` again

## Database connection fails

* Confirm `DATABASE_URL`
* Verify database is running
* Check firewall rules

## Image upload fails

* Check file size limits
* Confirm `multer` configuration
* Verify cloud storage credentials

---

# ğŸ“Š Data Export

Supported formats:

* CSV
* GeoJSON
* JSON API endpoint

Future:

* Integration with GIS platforms
* Batch download for researchers

---

# ğŸ”’ Security Considerations

* Sanitize all user input
* Validate file types
* Rate-limit submissions
* Use HTTPS in production
* Role-based admin review system

---

# ğŸ“ˆ Future Enhancements

* AI-assisted species identification
* Wetland health scoring system
* SMS submission option
* Offline-first mobile experience
* Dashboard analytics for municipalities

---

# ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Submit pull request
4. Include test coverage

---

# ğŸ“œ License

MIT License (or appropriate conservation-aligned license)


